{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1da259-fe24-45bc-9a26-06b0654a4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98c1e73-1b2b-47c4-9e62-50b82a002736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Epileptic Seizure Recognition.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a863efe-c5d7-49aa-afa3-6114d9cd61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].replace({2: 0, 3: 0, 4: 0, 5: 0})\n",
    "X = df.loc[:, df.columns.difference(['y', 'Unnamed'])]\n",
    "y = df['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a08cea6-3882-48aa-aa6d-b786910e3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f58af60-993f-45ab-9a55-27014834477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512f2cfa-993e-4995-ab06-fd8f23d50145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with cost-sensitive learning\n",
    "svm = SVC(probability=True, class_weight={0: 1, 1: 3}, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_probs = svm.predict_proba(X_test)[:, 1]\n",
    "svm_preds = svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73bef72-5282-4a85-aa22-8923a4900925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "#xgb = XGBClassifier(eval_metric='logloss')\n",
    "#xgb.fit(X_train, y_train)\n",
    "#xgb_probs = xgb.predict_proba(X_test)[:, 1]\n",
    "#xgb_preds = xgb.predict(X_test)\n",
    "\n",
    "# Count class imbalance\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# XGBoost with cost-sensitive learning\n",
    "xgb = XGBClassifier(\n",
    "                    eval_metric='aucpr',\n",
    "                    scale_pos_weight=scale_pos_weight,\n",
    "                    random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_probs = xgb.predict_proba(X_test)[:, 1]\n",
    "xgb_preds = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d86d12c-207e-4fed-adf4-15d5c751d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1840, number of negative: 7360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45390\n",
      "[LightGBM] [Info] Number of data points in the train set: 9200, number of used features: 178\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200000 -> initscore=-1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\mldl_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Make sure y_train is also a NumPy array\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "neg, pos = np.bincount(y_train_np)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# Initialize LightGBM\n",
    "lgbm = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    metric='auc',\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "# Fit model (X_train and y_train are already NumPy arrays)\n",
    "lgbm.fit(X_train, y_train_np)\n",
    "\n",
    "# Predict probabilities\n",
    "lgbm_probs = lgbm.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c39eec-6017-4393-93e9-c915fd13d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(class_weight={0: 1, 1: 3}, max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg_probs = log_reg.predict_proba(X_test)[:, 1]\n",
    "log_reg_preds = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb89dad-1177-4282-a637-6fc6ed364d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_probs = knn.predict_proba(X_test)[:, 1]\n",
    "knn_preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "395e6e7d-ad44-4f5f-9885-65ffc9438915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# ANN\n",
    "from tensorflow.keras import Input\n",
    "ann = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ann.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "ann_probs = ann.predict(X_test).flatten()\n",
    "ann_preds = (ann.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f591878c-7133-4674-bbf1-dd2ad961141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input for RNN, LSTM, CNN+BiLSTM\n",
    "X_train_seq = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_seq = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb165f3-dcb9-4335-b237-5404a8c9174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "from tensorflow.keras.layers import GRU\n",
    "gru = Sequential([\n",
    "    Input(shape=(X_train_seq.shape[1], 1)),\n",
    "    GRU(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "gru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "gru.fit(X_train_seq, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "gru_probs = gru.predict(X_test_seq).flatten()\n",
    "gru_preds = (gru_probs > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54ae177-eccb-41b3-9b65-2d2bf1214723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "lstm = Sequential([\n",
    "    Input(shape=(X_train_seq.shape[1], 1)),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm.fit(X_train_seq, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "lstm_probs = lstm.predict(X_test_seq).flatten()\n",
    "lstm_preds = (lstm_probs > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11ad7c5-f677-43f9-97d4-8a9a404f308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# RNN\n",
    "rnn = Sequential([\n",
    "    Input(shape=(X_train_seq.shape[1], 1)),\n",
    "    SimpleRNN(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn.fit(X_train_seq, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "rnn_probs = rnn.predict(X_test_seq).flatten()\n",
    "rnn_preds = (rnn_probs > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5499fd1e-f757-42e2-94ce-a1b121828830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# CNN + BiLSTM\n",
    "input_layer = Input(shape=(X_train_seq.shape[1], 1))\n",
    "x = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "cnn_bilstm_model = Model(inputs=input_layer, outputs=output)\n",
    "cnn_bilstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_bilstm_model.fit(X_train_seq, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "cnn_bilstm_probs = cnn_bilstm_model.predict(X_test_seq).flatten()\n",
    "cnn_biltsm_preds = (cnn_bilstm_probs > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "940b1ace-bd72-4f4f-9749-2fb084333e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Dropout, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Transformer Encoder Block\n",
    "def transformer_encoder_block(inputs, head_size=64, num_heads=2, ff_dim=128, dropout=0.1):\n",
    "    # Multi-head self-attention\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads)(inputs, inputs)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x + inputs)  # Residual\n",
    "\n",
    "    # Feed-forward network\n",
    "    ff = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff = Dense(inputs.shape[-1])(ff)\n",
    "    ff = Dropout(dropout)(ff)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x + ff)  # Residual\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa29bd0b-2be8-4481-b312-0cb07460c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "transformer_input = Input(shape=(X_train_seq.shape[1], 1))\n",
    "\n",
    "# Transformer block\n",
    "x = transformer_encoder_block(transformer_input)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "transformer_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Model\n",
    "transformer_model = Model(inputs=transformer_input, outputs=transformer_output)\n",
    "transformer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "transformer_model.fit(X_train_seq, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "# Predictions\n",
    "transformer_probs = transformer_model.predict(X_test_seq).flatten()\n",
    "transformer_preds = (transformer_probs > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b60ff9-8771-414e-89d3-5c55cd7da565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add\n",
    "\n",
    "def resnet_block(inputs, filters, kernel_size, stride=1):\n",
    "    x = Conv1D(filters, kernel_size, strides=stride, padding='same', activation='relu')(inputs)\n",
    "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    shortcut = Conv1D(filters, 1, strides=stride, padding='same')(inputs)  # match dimensions\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e409cf76-d20d-4a32-9d18-6dc974409124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Activation\n",
    "\n",
    "resnet_input = Input(shape=(X_train_seq.shape[1], 1))\n",
    "\n",
    "x = resnet_block(resnet_input, filters=64, kernel_size=3)\n",
    "x = resnet_block(x, filters=64, kernel_size=3)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "resnet_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "resnet_model = Model(inputs=resnet_input, outputs=resnet_output)\n",
    "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "resnet_model.fit(X_train_seq, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "resnet_probs = resnet_model.predict(X_test_seq).flatten()\n",
    "resnet_preds = (resnet_probs > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d65028c-7936-4773-b5c7-d349be8955e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step\n"
     ]
    }
   ],
   "source": [
    "attn_input = Input(shape=(X_train_seq.shape[1], 1))\n",
    "x = LSTM(64, return_sequences=True)(attn_input)\n",
    "x = MultiHeadAttention(num_heads=2, key_dim=64)(x, x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "attn_output = Dense(1, activation='sigmoid')(x)\n",
    "attn_model = Model(inputs=attn_input, outputs=attn_output)\n",
    "attn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "attn_model.fit(X_train_seq, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "attn_probs = attn_model.predict(X_test_seq).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a868ca-fd40-40d8-b2f9-db09403c467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_accuracy = 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\mldl_env\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "\n",
    "# Convert data to float32 (TabNet requires this)\n",
    "X_train_tabnet = X_train.astype(np.float32)\n",
    "X_test_tabnet = X_test.astype(np.float32)\n",
    "y_train_tabnet = y_train.values if hasattr(y_train, 'values') else y_train\n",
    "y_test_tabnet = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "\n",
    "# TabNet model\n",
    "tabnet = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "tabnet.fit(\n",
    "    X_train=X_train_tabnet,\n",
    "    y_train=y_train_tabnet,\n",
    "    eval_set=[(X_test_tabnet, y_test_tabnet)],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Predict probabilities and hard labels\n",
    "tabnet_probs = tabnet.predict_proba(X_test_tabnet)[:, 1]\n",
    "tabnet_preds = (tabnet_probs > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65bb7851-051f-4727-9067-b61c8668e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Averaging (Soft Voting)\n",
    "avg_probs = (svm_probs + xgb_probs + lgbm_probs + ann_probs + lstm_probs + gru_probs + rnn_probs + cnn_bilstm_probs + resnet_probs + attn_probs + transformer_probs ) / 11\n",
    "ensemble_preds = (avg_probs > 0.4).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cfe12a4-ddbf-4f45-890a-fd80b870e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ensemble Model Averaging Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1840\n",
      "           1       0.95      0.96      0.96       460\n",
      "\n",
      "    accuracy                           0.98      2300\n",
      "   macro avg       0.97      0.98      0.97      2300\n",
      "weighted avg       0.98      0.98      0.98      2300\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1819   21]\n",
      " [  17  443]]\n",
      "Accuracy: 0.9834782608695652\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"\\n--- Ensemble Model Averaging Results ---\")\n",
    "print(classification_report(y_test, ensemble_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, ensemble_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, ensemble_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9aa0050-5af7-4e59-a853-cfc2642cba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (Recall): 0.9630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_test and ensemble_preds are already defined\n",
    "cm = confusion_matrix(y_test, ensemble_preds)\n",
    "\n",
    "# Extract True Positives and False Negatives\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "\n",
    "# Calculate Sensitivity\n",
    "sensitivity = TP / (TP + FN)\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dde71-92fd-4df0-9120-7bdd2fbd3346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717d91e-afba-408b-b6d9-22bc8dce6951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mldl_env)",
   "language": "python",
   "name": "mldl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
